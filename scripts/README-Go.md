# Go Data Ingestion Tool

A high-performance Go-based data ingestion tool for processing large healthcare insurance JSON files and inserting them into Aurora MySQL database.

## üöÄ Features

- **High Performance**: Multi-threaded processing with configurable worker pools
- **Large File Support**: Handles files of any size with streaming processing
- **Compression Support**: Automatically handles `.json.gz` compressed files
- **Batch Processing**: Efficient database operations with connection pooling
- **Progress Tracking**: Real-time progress updates during processing
- **Error Handling**: Comprehensive error handling with detailed logging
- **Transaction Safety**: Database transactions ensure data integrity

## üìã Prerequisites

1. **Go 1.22+** installed on your system
2. **Aurora MySQL** database accessible from your network
3. **Environment variables** configured for database connection

## üõ†Ô∏è Installation

1. **Navigate to scripts directory**:
   ```bash
   cd scripts
   ```

2. **Install Go dependencies**:
   ```bash
   go mod tidy
   ```

3. **Build the binary**:
   ```bash
   go build -o ingest-data ingest-data.go
   ```

## ‚öôÔ∏è Configuration

Create a `.env` file in the project root with your Aurora database credentials:

```env
DB_HOST=price-transparency-db.cluster-ckrc4kwgypo0.us-east-1.rds.amazonaws.com
DB_PORT=3306
DB_USER=admin
DB_PASSWORD=your-password-here
DB_NAME=healthcare_saver
DB_SSL=true
```

## üéØ Usage

### Process a Single File

```bash
# From project root
./scripts/ingest-data -file /path/to/your/data.json -workers 10

# From scripts directory
./ingest-data -file /path/to/your/data.json -workers 10
```

### Process Compressed Files

```bash
# Automatically handles .json.gz files
./scripts/ingest-data -file /path/to/your/data.json.gz -workers 10
```

### Process All Files in a Directory

```bash
# Process all .json and .json.gz files in a directory
./scripts/ingest-data -dir /path/to/your/data/directory -workers 10
```

### Command Line Options

- `-file`: Path to a single file to process
- `-dir`: Path to a directory containing files to process
- `-workers`: Number of worker goroutines (default: 10)

## üìä Performance Optimization

### Worker Count
- **Small files (< 100MB)**: 5-10 workers
- **Medium files (100MB-1GB)**: 10-20 workers  
- **Large files (> 1GB)**: 20-50 workers

### Database Connection Pool
The tool automatically configures:
- Max open connections: 25
- Max idle connections: 25
- Connection lifetime: 5 minutes

## üóÑÔ∏è Database Schema

The tool creates two optimized tables:

### `insurance_services`
```sql
CREATE TABLE insurance_services (
  id INT AUTO_INCREMENT PRIMARY KEY,
  negotiation_arrangement VARCHAR(50) NOT NULL,
  name VARCHAR(500) NOT NULL,
  billing_code_type VARCHAR(20) NOT NULL,
  billing_code_type_version VARCHAR(20) NOT NULL,
  billing_code VARCHAR(50) NOT NULL,
  description TEXT,
  created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
  updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP,
  INDEX idx_billing_code (billing_code),
  INDEX idx_name (name),
  INDEX idx_negotiation_arrangement (negotiation_arrangement)
);
```

### `negotiated_rates`
```sql
CREATE TABLE negotiated_rates (
  id INT AUTO_INCREMENT PRIMARY KEY,
  service_id INT NOT NULL,
  provider_references JSON NOT NULL,
  negotiated_type ENUM('percentage', 'negotiated') NOT NULL,
  negotiated_rate DECIMAL(15,2) NOT NULL,
  expiration_date DATE NOT NULL,
  service_codes JSON NOT NULL,
  billing_class ENUM('professional', 'institutional') NOT NULL,
  created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
  updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP,
  FOREIGN KEY (service_id) REFERENCES insurance_services(id) ON DELETE CASCADE,
  INDEX idx_service_id (service_id),
  INDEX idx_negotiated_type (negotiated_type),
  INDEX idx_billing_class (billing_class),
  INDEX idx_expiration_date (expiration_date)
);
```

## üìà Expected Performance

Based on testing with typical healthcare data:

- **Processing Speed**: 10,000-50,000 records per minute (depending on worker count)
- **Memory Usage**: ~100-500MB (depending on file size and worker count)
- **Database Throughput**: 1,000-5,000 inserts per second

## üîß Troubleshooting

### Network Connectivity Issues

If you get `no such host` errors:

1. **Check VPC/Security Groups**: Ensure Aurora is accessible from your network
2. **Test DNS Resolution**: 
   ```bash
   nslookup price-transparency-db.cluster-ckrc4kwgypo0.us-east-1.rds.amazonaws.com
   ```
3. **Test Database Connection**:
   ```bash
   mysql -h price-transparency-db.cluster-ckrc4kwgypo0.us-east-1.rds.amazonaws.com -u admin -p
   ```

### Memory Issues

If you encounter memory issues with very large files:

1. **Reduce worker count**: Use fewer workers
2. **Process in chunks**: Split large files into smaller pieces
3. **Increase system memory**: Add more RAM to your system

### Database Connection Issues

1. **Check credentials**: Verify username/password in `.env`
2. **Check SSL settings**: Set `DB_SSL=false` if SSL is not required
3. **Check database name**: Ensure the database exists

## üìù Example Output

```
üèóÔ∏è Creating database tables...
‚úÖ Database tables created successfully
üìÅ Processing file: /path/to/data.json.gz
üìä Processed 1000 lines, 1500 services
üìä Processed 2000 lines, 3000 services
üìä Processed 3000 lines, 4500 services
üéâ Successfully processed 3500 lines, 5250 services from /path/to/data.json.gz

üìä Database Statistics:
   Services: 5250
   Negotiated Rates: 15750
üéâ Data ingestion completed successfully!
```

## üîÑ Integration with Your Workflow

### For Google Colab/Cloud Processing

```bash
# Download and build
wget https://go.dev/dl/go1.22.0.linux-amd64.tar.gz
tar -C /usr/local -xzf go1.22.0.linux-amd64.tar.gz
export PATH=$PATH:/usr/local/go/bin

# Build the tool
cd /content/healthcare_saver/scripts
go mod tidy
go build -o ingest-data ingest-data.go

# Process files
./ingest-data -file /content/data.json.gz -workers 20
```

### For AWS EC2 Processing

```bash
# Install Go
sudo yum install golang -y

# Build and run
cd /path/to/healthcare_saver/scripts
go mod tidy
go build -o ingest-data ingest-data.go
./ingest-data -file /path/to/data.json.gz -workers 20
```

## üÜö Comparison with TypeScript Version

| Feature | Go Version | TypeScript Version |
|---------|------------|-------------------|
| Performance | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê | ‚≠ê‚≠ê‚≠ê |
| Memory Usage | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê | ‚≠ê‚≠ê‚≠ê |
| Large File Support | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê | ‚≠ê‚≠ê‚≠ê |
| Setup Complexity | ‚≠ê‚≠ê‚≠ê | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê |
| Development Speed | ‚≠ê‚≠ê‚≠ê | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê |
| Production Ready | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê | ‚≠ê‚≠ê‚≠ê‚≠ê |

The Go version is recommended for:
- Large datasets (> 100MB)
- Production environments
- High-performance requirements
- Batch processing workflows 